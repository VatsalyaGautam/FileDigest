```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   
â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•   â•šâ•â•   
```
# ğŸ–‡ï¸ FileDigest

A Multithreaded File Hasher with a Real-time Terminal UI

FileDigest is a powerful file hashing tool written in Rust that makes computing file checksums fast and easy. It can process multiple files at once using parallel processing, and shows you live progress right in your terminal as it works through your files.

â¸»

## ğŸ“Œ Key Features

	â€¢	âš¡ Parallel hashing using worker threads
	â€¢	ğŸ—‚ï¸ Recursive directory traversal (optional)
	â€¢	ğŸ–¥ï¸ Live TUI showing Pending â†’ Working â†’ Done/Error
	â€¢	ğŸ§µ Configurable worker count
	â€¢	ğŸ” BLAKE3 hashing (fast, secure, incremental)
	â€¢	âš ï¸ Strong validation for invalid paths, symlinks, sockets, FIFOs, devices, etc.
	â€¢	ğŸ§± Robust error model (thiserror + anyhow)
	â€¢	ğŸ“¦ Cross-platform (Linux/macOS/Windows)

â¸»

## ğŸ—ï¸ High-Level Architecture

![Architecture Diagram](docs/flow_diagram.png)

â¸»

## ğŸ”„ Code Flow Explained

Here's what happens behind the scenes when you run the program:

### 1. CLI Parsing (cli.rs)

First, the program reads your input to understand what you want:
	â€¢	Which files or folders you want to hash
	â€¢	How many threads to use (--threads)
	â€¢	Whether to dive into subdirectories (--recursive)

Before doing any actual work, it makes sure everything looks good by:
	â€¢	Checking that all paths are valid
	â€¢	Removing any duplicates you might have accidentally included
	â€¢	Filtering out things that can't be hashed (like symlinks, special system files, or files you don't have permission to read)

What you get:
A clean, verified list of files that are ready to be processed.

â¸»

### 2. File Discovery (jobs.rs)

Next, the program examines each path you provided:
	â€¢	If it's a file â†’ adds it directly to the work queue
	â€¢	If it's a directory â†’ scans through it to find all the files inside (going deeper into subdirectories if you asked for that)

For every actual file it finds, it creates a FileRecord that tracks its journey:

Pending -> Working -> Done / Error

These records get sent to:
	â€¢	The job queue where workers will pick them up
	â€¢	The display interface so you can watch the progress

â¸»

### 3. Worker Thread Pool (jobs.rs)

The program then creates a team of worker threads (think of them as parallel workers all doing the same job):

Each worker follows a simple routine:
	1.	Grabs the next file from the queue
	2.	Updates its status to "Working"
	3.	Calculates the hash using BLAKE3, piece by piece
	4.	Reports back with either:
	â€¢	Success and the computed hash
	â€¢	An error message if something went wrong

These workers run completely independently, which means they can all process different files at the same time without waiting for each other.

â¸»

### 4. File Hashing Engine (file_hash.rs)

When a worker hashes a file, here's what happens:
	â€¢	Opens the file
	â€¢	Reads it in manageable chunks (not all at once)
	â€¢	Feeds each chunk into the BLAKE3 hasher
	â€¢	Produces the final hash as a readable hexadecimal string

This chunk-by-chunk approach means even huge files won't overwhelm your computer's memory.

â¸»

### 5. Real-Time TUI (tui.rs)

While all this is happening, the main program keeps the display updated.

It's constantly watching for:
	â€¢	Updates from workers about their progress
	â€¢	Your keyboard input (in case you want to quit with 'q' or Ctrl+C)

Every time something changes:
	â€¢	The display updates to show a file's new status:
	â€¢	Pending â†’ Working
	â€¢	Working â†’ Done
	â€¢	Working â†’ Error

The display closes automatically when:
	â€¢	Every file has been processed, and
	â€¢	All workers have finished their jobs

â¸»

### 6. Graceful Shutdown

Once everything's complete:
	â€¢	Workers naturally finish up (since there's no more work)
	â€¢	The display closes cleanly
	â€¢	Your terminal returns to normal

And you're done!

â¸»

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ main.rs         # Entry point: CLI -> jobs -> TUI orchestration
â”œâ”€â”€ lib.rs          # Exposes main functionality for tests
â”œâ”€â”€ cli.rs          # All clap argument parsing + validation
â”œâ”€â”€ jobs.rs         # Worker threads, job/status channels, file discovery
â”œâ”€â”€ file_hash.rs    # BLAKE3 incremental hashing
â”œâ”€â”€ tui.rs          # ratatui-based UI for real-time updates
â”œâ”€â”€ utils.rs        # Helper utilities (e.g., truncate_middle)
â””â”€â”€ error.rs        # Custom error types (thiserror)
```

â¸»

## ğŸ§  Module Responsibilities (What Each Part Does)

### main.rs
	â€¢	Reads and interprets your command-line input
	â€¢	Gathers all the file paths
	â€¢	Sets up the list of files to process
	â€¢	Launches the worker threads
	â€¢	Keeps the live display running
	â€¢	Waits for all workers to finish

### cli.rs
	â€¢	Defines what arguments you can use
	â€¢	Makes sure your inputs are valid
	â€¢	Blocks anything that shouldn't be hashed

### jobs.rs
	â€¢	Finds all the files using directory scanning
	â€¢	Sets up communication channels between workers and the main program
	â€¢	Contains the logic that workers follow
	â€¢	Sends progress updates to the display

### file_hash.rs
	â€¢	Opens and reads files
	â€¢	Computes the BLAKE3 hash piece by piece
	â€¢	Returns the hash as a hex string

### tui.rs
	â€¢	Takes control of your terminal
	â€¢	Draws the live results table
	â€¢	Updates rows as files get processed
	â€¢	Handles when you want to exit

### error.rs
	â€¢	Provides clear, specific error types
	â€¢	Makes it easy to handle and report problems

â¸»

## ğŸš€ Getting Started

Want to try it out? Here's how to get FileDigest running on your machine:

### 1. Clone the Repository

First, grab a copy of the project:

```bash
git clone https://github.com/yourusername/filedigest.git
cd filedigest
```

Or if you want to make your own modifications, fork it first on GitHub and then clone your fork.

### 2. Create a Test File

Let's create a simple test file in the project directory:

```bash
echo "Hello, FileDigest!" > myfile.txt
```

### 3. Run It!

Now you can hash your file using cargo:

```bash
cargo run -- myfile.txt
```

That's it! You'll see the live terminal interface showing your file being processed and its hash being computed.

â¸»

## âš™ï¸ Usage Examples

Once you've built the project, here are different ways to use it:

### Hash a single file

cargo run -- ./example.txt

Or if you've installed it:

filedigest ./example.txt

### Hash a folder with 4 threads

cargo run -- ./folder -t 4

### Hash without going into subdirectories

cargo run -- ./folder --no-recursive

### Hash multiple files at once

cargo run -- file1.txt file2.txt folder/


â¸»

## ğŸ”§ Dependencies
	â€¢	blake3 â€” cryptographic hashing
	â€¢	walkdir â€” directory traversal
	â€¢	crossbeam-channel â€” fast MPMC channels
	â€¢	crossterm â€” keyboard I/O & terminal control
	â€¢	ratatui â€” TUI rendering
	â€¢	clap â€” CLI parsing
	â€¢	thiserror + anyhow â€” error handling

â¸»

## ğŸ§ª Tests

Run all tests

cargo test

Integration tests use tempfile to avoid touching real filesystem.

â¸»

## ğŸš€ Future Improvements
	â€¢	Output results into JSON/CSV
	â€¢	Support SHA-256, SHA-512
	â€¢	Hash verification mode
	â€¢	File-type filters
	â€¢	Progress percentage per-file

â¸»